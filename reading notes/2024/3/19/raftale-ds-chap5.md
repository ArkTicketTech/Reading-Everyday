## 乐观并发控制

两类：

1. 基于检查的并发控制：

    1. 读取：复制一份副本放到一个私有空间，写操作被记录到私有空间中；

    1. 校验：检查此期间事务是否与其他事务发生冲突，发生则中止，反之提交事务

    1. 写入：数据复制到存储的位置进行覆盖

1. 基于时间戳的并发控制：

    1. 很像一个没有锁的读写锁

    1. 如何判断锁冲突是通过时间戳来实现的。

    1. 每个数据项和每个事务都会分配时间戳。

        1. 数据项会记录两个时间戳，最近一次被写入的时间戳和最近一次被读取的时间戳

        1. 事务开始有一个时间戳

    1. 事务提交时会进行时间戳的检查，

        1. 对于读事务，如果事务的时间戳早于写入的时间戳，说明读取到了未来的数据，则中止事务；反之则正常

        1. 对于写事务，如果事务的时间戳早于读或者写的时间戳，说明修改了已经被未来某个事务读取活着写入的数据项，则中止事务；反之正常。这里表明了写与读、写冲突。

    1. 中止的事务会进行重试

    1. 优点：事务不必相互等待，不会有死锁；性能高；

    1. 缺点：需要实现全局时钟保证准

## 多版本并发控制

多版本并发控制可以看作在乐观并发控制的基础上增加了多个版本，即为每个数据项存储多个版本，每个事务读到的都是某个版本的数据项，写操作不覆盖已有的数据，而是新建一个新的版本，直到事务提交后才变为可见。这样一来，正在执行写操作的事务不会阻塞需要读取相同数据的事务。因此，多版本并发控制有着非常好的读性能，适合实现快照隔离的隔离级别。



### 多版本两阶段锁

在两阶段锁协议的基础上增加了多个版本。

1. 读操作：搜索事务可以读取的最新版本 ，并判断其他事务是否持有该数据项的锁，持有则中止并回滚；否则就读取数据；
2. 写操作：先找到最新版本的数据项，并判断是否有其他事务持有该数据的读写锁，没有则执行写操作，创建一个新的版本；有冲突就回滚。

然后是如何处理死锁，最好的策略是无等待算法，即立即中止，稍后重试。



具体的实现大概是：

1. txn-id：记录当前数据项的写锁的事务的开始时间戳。没有事务持有则为0，表明可以安全访问。
2. begin-ts：事务提交时间戳
3. end-ts：如果该数据项为最新版本，则其为无限大；反之则比begin-ts小（上一个版本的beign-ts）
4. read-cnt：当前数据项读锁的数量



通过判断事务开始时间在 begin-ts和end-ts之间 来确定最新版本。

通过txn-id和read-cnt可以判断是否持有读锁和写锁。



Oracle、Postgres和MySQL-InnoDB都是使用的多版本两阶段锁。

### 多版本乐观并发控制

基于检查的乐观并发控制





### 多版本时间戳排序

多版本时间戳排序是在基于时间戳的并发控制的基础上增加版本，是最早的并发控制算法。





### 版本存储和垃圾回收

多版本并发控制的代价是，每个数据项都存储多个版本是需要成本的，随着时间推移，还需要一定的策略对过期的版本进行垃圾回收，以回收存储空间。

1. 仅追加存储：所有元组存储在同一张表中，新版本数据追加到现有元组列表中，然后修改指针指向新元组

    1. 变化一个字段时，需要复制其他所有字段，如果遇到大的text字段，则会降低性能

    1. Postgres、MemSQL等系统使用

1. 时间旅行存储：单独用一个时间旅行表来存储历史版本，而最新版本的数据存储在主表中。新增一个新版本的元组时，先在时间旅行表中增加一行，然后将主表的数据复制到这个位置，最后修改主表中的最新版本。
    1. 缺点：对于大的text，性能较差

1. 增量存储：每次只将发生变化的字段信息存储到增量存储中。新增新版本时，系统将字段修改信息存储到增量存储中，这里只存储修改的属性而不是完整的属性，最后系统再直接修改主表信息。

    1. 增量存储在MySQL中被称为回滚段，回滚事务就是利用它

    1. 对于写频繁操作的工作负载，可以减少内存分配；对于读操作频繁的，需要访问回滚段才能重新拼出需要的信息，开销会高点



另一方面，存储的版本信息需要一定策略进行垃圾回收。

1. 元组级别垃圾回收
    1. 后台清理
    2. 协同清理：执行事务的时候进行清理

1. 事务级别垃圾回收

### 小结

多版本并发控制非常适合以读请求为主要负载的系统，因此主流数据库都实现了多版本并发控制。

但快照隔离并不是串性化，仍然会发生写偏斜，串性化的快照隔离（SSI）被提出来，可以防止写偏斜，并在PostgreSQL 9.1 中被采用。

思想是：通过跟踪事务的读写操作，按照时间戳生成一个图，如果监测到图中存在环，则违背了串性化，需要中止其中一个事务来实现串性化。

SSI在DDIA第7章有提及，原理就是说：

1. 在数据修改之后（此时还未提交）读取数据，当读取检测到是陈旧的读取时，在提交的时候如果自身有写操作就进行中止并重试。
2. 在数据修改之前（此时还未提交）读取数据，当修改数据时发现是陈旧的数据时，先提交的通知后提交的事务读取的数据不是最新的了，请进行中止并重试。

如何发现陈旧的数据，可能就是上面说到的检测图中是否存在环的手段吧，具体怎么实现没说，也没想清楚。





# 本章小结

本章重点讨论了分布式事务的原子性和隔离性。

原子性：

1. 两阶段提交
2. 三阶段提交：消息轮次过多
3. Paxos提交：实现复杂
4. Quorum提交：很少用于生产
5. Sega事务：耦合性较低，但不满足ACID，很少用于生产

首选还是两阶段提交。


隔离性：

1. 悲观并发控制：额外开销
2. 乐观并发控制：大量冲突导致大量重试
3. 多版本并发控制：大量冲突导致大量重试



总结下就是有些算法要么引入了单点故障或阻塞问题，要么给系统带来了额外的复杂度。分布式系统下实现事务开销较高，所以很少有分布式系统实现完整的ACID。
