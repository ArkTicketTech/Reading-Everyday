## Testing analyzers

å¦‚æœè¦çœ‹åˆ†è¯çš„ç»“æœï¼Œä½¿ç”¨`_analyze`ã€‚

```json
GET _analyze
{
  "text": "James Bond 007"
}

// output:
{
  "tokens" : [
    {
      "token" : "james",
      "start_offset" : 0,
      "end_offset" : 5,
      "type" : "<ALPHANUM>",
      "position" : 0
    },
    {
      "token" : "bond",
      "start_offset" : 6,
      "end_offset" : 10,
      "type" : "<ALPHANUM>",
      "position" : 1
    },
    {
      "token" : "007",
      "start_offset" : 11,
      "end_offset" : 14,
      "type" : "<NUM>",
      "position" : 2
    }
  ]
}
```

ALPHANUM for a string, NUM for a numeric token.

ä¸ä¼ analyzeré»˜è®¤standard analyzerï¼Œå¯æŒ‡å®šanalyzer

```json
GET _analyze
{
  "text": "James Bond 007",
  "analyzer": "simple"
}

output:
{
  "tokens" : [
    {
      "token" : "james",
      "start_offset" : 0,
      "end_offset" : 5,
      "type" : "word",
      "position" : 0
    },
    {
      "token" : "bond",
      "start_offset" : 6,
      "end_offset" : 10,
      "type" : "word",
      "position" : 1
    }
  ]
}
```

`_analyze`è¿˜å¯ä»¥æŒ‡å®štokenizerå’Œfilteråä½¿ç”¨ï¼š

```json
GET _analyze
{
  "text": "/Volumes/FILES/Dev",
  "tokenizer": "path_hierarchy",
  "filter": [
    "uppercase"
  ]
}
```

# Built-in analyzers

å…«ç§analyzerï¼š

1. standardï¼šdefault analyzer
2. simple
3. stop
4. whitespace
5. keyword
6. language
7. pattern
8. fingerprint

## standard analyzer

```json
GET _analyze
{
  "analyzer": "standard",
  "text": "Hot cup of â˜• and a ğŸ¿is a Weird Combo :(!!"
}
```

stop filteré»˜è®¤ä¸å¼€å¯ï¼Œå¯é…ç½®å¼€å¯

```json
#Configuring analyzers

PUT my_index_with_stopwords
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_with_stopwords":{ # names the analyzer
          "type":"standard",
          "stopwords":"_english_"  # enables the English stop words filter
        }
      }
    }
  }
}
```



```json
POST my_index_with_stopwords/_analyze
{
  "text": ["Hot cup of â˜• and a ğŸ¿is a Weird Combo :(!!"],
  "analyzer": "standard_with_stopwords"
}
```

of, a, is è¿™äº›è¯å°†ä¸å†å‡ºç°åœ¨åˆ†è¯ä¸­ã€‚



ä¹Ÿå¯ä»¥å°†stop wordsæ”¾åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œè¿™ä¸ªæ–‡ä»¶çš„ä½ç½®æ˜¯æ”¾ç½®åœ¨`$ELASTICSEARCH_HOME/config` ä¸­çš„ã€‚

```json
# Index with custom swear words 
PUT index_with_swear_stopwords
{
  "settings": {
    "analysis": {
      "analyzer": {
        "swearwords_analyzer":{
          "type":"standard",
          "stopwords_path":"swearwords.txt"
        }
      }
    }
  }
}

POST index_with_swear_stopwords/_analyze
{
  "text": ["Damn, that sucks!"],
  "analyzer": "swearwords_analyzer"
}
```



### Configuring the token length

```json
## Setting token length
DELETE my_index_with_max_token_length
PUT my_index_with_max_token_length
{
  "settings": {
    "analysis": {
      "analyzer": {
        "standard_max_token_length":{
          "type":"standard",
          "max_token_length":7
        }
      }
    }
  }
}
```

æ¯”å¦‚`Elasticsearch`å°±ä¼šè¢«æ‹†åˆ†ä¸º`Elastic, search`ã€‚
