机器学习的种类

- **监督学习（Supervised Learning）**
    - **定义**：在监督学习中，模型在带有标签的数据集上进行训练。目标是学习从输入到输出的映射
    - **应用**：手写文字识别、声音处理、图像处理、垃圾邮件分类与拦截、网页检索、基因诊断以及股票预测等
    - **算法**：线性回归、逻辑回归、支持向量机、决策树、随机森林、神经网络等
- **无监督学习（Unsupervised Learning）**
    - **定义**：无监督学习在没有标签的数据上进行训练，目标是发现数据的结构或模式
    - **应用**：聚类（如客户分群）、降维（如主成分分析）,(人造卫星故障诊断、视频分析、社交网站解析和声音信号解析等 ?)
    - **算法**：K均值聚类、层次聚类、主成分分析（PCA）、自编码器等
- **半监督学习（Semi-supervised Learning）**
    - **定义**：结合了少量标记数据和大量未标记数据进行训练
    - **应用**：适用于标记数据获取成本高的场景，如图像分类
    - **算法**：通常是监督和无监督学习算法的结合
- **强化学习（Reinforcement Learning）**
    - **定义**：通过与环境的交互来学习策略，目标是通过试错法最大化累积奖励
    - **应用**：游戏AI、机器人控制、自动驾驶,(机器人的自动控制、计算机游戏中的人工智能、市场战略的最优化等 )
    - **算法**：Q学习、深度Q网络（DQN）、策略梯度方法、A3C等
- **自监督学习（Self-supervised Learning）**
    - **定义**：从数据本身生成标签进行训练，通常用于生成特征表示
    - **应用**：自然语言处理中的词嵌入、图像处理中的特征提取
    - **算法**：BERT、GPT等
- **迁移学习（Transfer Learning）**
    - **定义**：将从一个任务中学到的知识应用到相关但不同的任务中
    - **应用**：在计算机视觉中使用预训练模型进行特定任务的微调
    - **算法**：通常涉及预训练模型的使用和微调

- 回归
    - 主要用于预测连续值
    - 回归分析的目标是找到一个函数，该函数可以根据输入变量（特征）预测输出变量（目标值）
    - **实函数近似**
        - 回归问题可以被视为寻找一个实函数 $*f(x)*$，这个函数能够近似地描述输入变量 $*x*$ 和输出变量 $*y*$ 之间的关系
        - 例如，房价预测
    - **样本点附近的近似**
        - 在回归中，使用一组已知的样本点（训练数据）来训练模型。这些样本点包括输入和对应的输出
        - 模型通过这些样本点学习输入和输出之间的关系，以便在新数据（测试数据）上进行预测
    - **有监督的函数近似问题**
        - 在训练模型时使用了带有标签的数据（?）
    - **常见的回归算法**
        - **线性回归**：假设输出是输入的线性组合
        - **多项式回归**：扩展线性回归，允许输入的多项式组合
        - **支持向量回归（SVR）**：使用支持向量机的思想进行回归
        - **决策树回归**：使用决策树来预测连续值
        - **随机森林回归**：集成多棵决策树的预测结果
        - **神经网络回归**：使用神经网络来捕捉复杂的非线性关系

- 分类
    - 对于指定的模式进行识别的有监督的模型识别问题
    - **输入和输出**
        - **输入**：与回归类似，分类问题也使用一组特征作为输入
        - **输出**：输出是一个类别标签，表示输入数据所属的类别，例如，垃圾分类
    - **目标**
        - 学习一个决策边界或规则，使得模型能够根据输入特征准确地预测类别标签
    - **常见的分类算法**
        - **逻辑回归**：尽管名字中有“回归”，但用于二分类问题
        - **支持向量机（SVM）**：用于找到最佳的决策边界
        - **决策树**：通过一系列决策规则进行分类
        - **随机森林**：集成多棵决策树的结果
        - **朴素贝叶斯**：基于贝叶斯定理的概率分类
        - **神经网络**：尤其是深度学习中的卷积神经网络（CNN）在图像分类中非常有效
    - **评估指标**
        - 常用的评估指标包括准确率、精确率、召回率、F1分数等
        - 对于不平衡数据集，可能需要使用ROC曲线和AUC值来评估模型性能
- 异常检测
    - 用于识别数据集中不符合预期模式的样本
    - **方法分类**
        - **有监督异常检测**
            - **定义**：使用带有正常和异常标签的数据进行训练
            - **方法**：可以使用传统的分类算法，如决策树、支持向量机（SVM）等
        - **无监督异常检测**
            - **定义**：不需要标签，模型通过识别与大多数数据不同的样本来检测异常
            - **方法**：常用方法包括聚类（如K-means）、密度估计（如局部异常因子LOF）、孤立森林（Isolation Forest）等
        - **半监督异常检测**
            - **定义**：使用仅包含正常样本的训练数据，模型学习正常行为，然后在测试时识别偏离正常行为的样本
            - **方法**：一类支持向量机（One-Class SVM）、自编码器（Autoencoder）等
    - **评估指标**
        - **准确率（Accuracy）**：在不平衡数据集中可能不够有效
        - **精确率（Precision）**：检测到的异常样本中实际异常的比例
        - **召回率（Recall）**：实际异常样本中被检测到的比例
        - **F1分数（F1 Score）**：精确率和召回率的调和平均
        - **ROC曲线和AUC值**：用于评估模型在不同阈值下的性能
    - **应用领域**
        - **网络安全**：检测入侵和恶意活动
        - **金融**：识别信用卡欺诈和异常交易
        - **工业监控**：预测设备故障和异常操作
        - **医疗**：检测异常的健康指标或病症
- 聚类 （TODO）